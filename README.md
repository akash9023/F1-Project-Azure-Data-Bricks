# F1 Project Azure DataBricks

### Data Ingestion
- Ingest 8 files in datalake
- Apply the schema
- Store the result in columnar format[parquet]
- Analyze data via SQL
- Handle Incremental Load
  
### Data TRansformation
- Join the key information for Reporting 
- Join the key information for Analysis
- Audit Columns for transformed tables
- Analyze transformed tabkes via SQL
- Store transformed tables in columnar format[parquet]
- Handle incremental load
  
### Reporting Requirements
- Driver Standings
- Constructor[Team] Standing
  
### Analysis Requirements
- Dominant drivers
- Dominant teams
- Visualize Outputs
- Databricks Dashboard
  
### Scheduling Requirements
- Monitor pipelines
- Re-Runs failed pipelines
- Set-up alerts on failures
- Schedule to run

### Individual Requirements
- Delete individual records
- See History & Time Travel
- Roll back to previous version
